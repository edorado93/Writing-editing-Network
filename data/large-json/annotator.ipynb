{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dictionary = {\"i\": \"INTRODUCTION\", \"b\": \"BODY\", \"c\": \"CONCLUSION\"}\n",
    "done_file = set(list(map(str.strip,open(\"done.txt\").readlines())))\n",
    "done = set()\n",
    "ignored_titles = set(list(map(str.strip,open(\"ignored.txt\").readlines())))\n",
    "write_to_file = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***************************** Abstract is: **************************\n",
      "mixed integer optimization has been a topic of active research in past decades\n",
      "it has been used to solve statistical problems of classification and regression involving massive data\n",
      "however , there is an inherent degree of vagueness present in huge real life data\n",
      "this impreciseness is handled by fuzzy sets\n",
      "in this paper , fuzzy mixed integer optimization method ( fmiom ) is used to find solution to regression problem\n",
      "the methodology exploits discrete character of problem\n",
      "in this way large scale problems are solved within practical limits\n",
      "the data points are separated into different polyhedral regions and each region has its own distinct regression coefficients\n",
      "in this attempt , an attention is drawn to statistics and data mining community that integer optimization can be significantly used to revisit different statistical problems\n",
      "computational experimentations with generated and real data sets show that fmiom is comparable to and often outperforms current leading methods\n",
      "the results illustrate potential for significant impact of fuzzy integer optimization methods on computational statistics and data mining .\n",
      "\n",
      " is this ok ? \n",
      "y\n",
      "mixed integer optimization has been a topic of active research in past decadesi\n",
      "it has been used to solve statistical problems of classification and regression involving massive datai\n",
      "however , there is an inherent degree of vagueness present in huge real life datai\n",
      "this impreciseness is handled by fuzzy setsi\n",
      "in this paper , fuzzy mixed integer optimization method ( fmiom ) is used to find solution to regression problemb\n",
      "the methodology exploits discrete character of problemb\n",
      "in this way large scale problems are solved within practical limitsb\n",
      "the data points are separated into different polyhedral regions and each region has its own distinct regression coefficientsb\n",
      "in this attempt , an attention is drawn to statistics and data mining community that integer optimization can be significantly used to revisit different statistical problemsb\n",
      "computational experimentations with generated and real data sets show that fmiom is comparable to and often outperforms current leading methodsc\n",
      "the results illustrate potential for significant impact of fuzzy integer optimization methods on computational statistics and data mining .c\n",
      "\n",
      "\n",
      "***************************** Abstract is: **************************\n",
      "in this study , we show that landmark detection or face alignment task is not a single and independent problem\n",
      "instead , its robustness can be greatly improved with auxiliary information\n",
      "specifically , we jointly optimize landmark detection together with the recognition of heterogeneous but subtly correlated facial attributes , such as gender , expression , and appearance attributes\n",
      "this is non-trivial since different attribute inference tasks have different learning difficulties and convergence rates\n",
      "to address this problem , we formulate a novel tasks-constrained deep model , which not only learns the inter-task correlation but also employs dynamic task coefficients to facilitate the optimization convergence when learning multiple complex tasks\n",
      "extensive evaluations show that the proposed task-constrained learning ( i ) outperforms existing face alignment methods , especially in dealing with faces with severe occlusion and pose variation , and ( ii ) reduces model complexity drastically compared to the state-of-the-art methods based on cascaded deep model .\n",
      "\n",
      " is this ok ? \n",
      "y\n",
      "in this study , we show that landmark detection or face alignment task is not a single and independent problemi\n",
      "instead , its robustness can be greatly improved with auxiliary informationb\n",
      "specifically , we jointly optimize landmark detection together with the recognition of heterogeneous but subtly correlated facial attributes , such as gender , expression , and appearance attributesb\n",
      "this is non-trivial since different attribute inference tasks have different learning difficulties and convergence ratesb\n",
      "to address this problem , we formulate a novel tasks-constrained deep model , which not only learns the inter-task correlation but also employs dynamic task coefficients to facilitate the optimization convergence when learning multiple complex tasksb\n",
      "extensive evaluations show that the proposed task-constrained learning ( i ) outperforms existing face alignment methods , especially in dealing with faces with severe occlusion and pose variation , and ( ii ) reduces model complexity drastically compared to the state-of-the-art methods based on cascaded deep model .c\n",
      "\n",
      "\n",
      "***************************** Abstract is: **************************\n",
      "many optimization problems arising in applications have to consider several objective functions at the same time\n",
      "evolutionary algorithms seem to be a very natural choice for dealing with multi-objective problems as the population of such an algorithm can be used to represent the trade-offs with respect to the given objective functions\n",
      "in this paper , we contribute to the theoretical understanding of evolutionary algorithms for multi-objective problems\n",
      "we consider indicator-based algorithms whose goal is to maximize the hypervolume for a given problem by distributing { \\mu } points on the pareto front\n",
      "to gain new theoretical insights into the behavior of hypervolume-based algorithms we compare their optimization goal to the goal of achieving an optimal multiplicative approximation ratio\n",
      "our studies are carried out for different pareto front shapes of bi-objective problems\n",
      "for the class of linear fronts and a class of convex fronts , we prove that maximizing the hypervolume gives the best possible approximation ratio when assuming that the extreme points have to be included in both distributions of the points on the pareto front\n",
      "furthermore , we investigate the choice of the reference point on the approximation behavior of hypervolume-based approaches and examine pareto fronts of different shapes by numerical calculations .\n",
      "\n",
      " is this ok ? \n",
      "y\n",
      "many optimization problems arising in applications have to consider several objective functions at the same timei\n",
      "evolutionary algorithms seem to be a very natural choice for dealing with multi-objective problems as the population of such an algorithm can be used to represent the trade-offs with respect to the given objective functionsi\n",
      "in this paper , we contribute to the theoretical understanding of evolutionary algorithms for multi-objective problemsb\n",
      "we consider indicator-based algorithms whose goal is to maximize the hypervolume for a given problem by distributing { \\mu } points on the pareto frontb\n",
      "to gain new theoretical insights into the behavior of hypervolume-based algorithms we compare their optimization goal to the goal of achieving an optimal multiplicative approximation ratioc\n",
      "our studies are carried out for different pareto front shapes of bi-objective problemsc\n",
      "for the class of linear fronts and a class of convex fronts , we prove that maximizing the hypervolume gives the best possible approximation ratio when assuming that the extreme points have to be included in both distributions of the points on the pareto frontc\n",
      "furthermore , we investigate the choice of the reference point on the approximation behavior of hypervolume-based approaches and examine pareto fronts of different shapes by numerical calculations .c\n",
      "\n",
      "\n",
      "***************************** Abstract is: **************************\n",
      "we present a novel method for exact hierarchical sparse polynomial regression\n",
      "our regressor is that degree $ r $ polynomial which depends on at most $ k $ inputs , counting at most $ \\ell $ monomial terms , which minimizes the sum of the squares of its prediction errors\n",
      "the previous hierarchical sparse specification aligns well with modern big data settings where many inputs are not relevant for prediction purposes and the functional complexity of the regressor needs to be controlled as to avoid overfitting\n",
      "we present a two-step approach to this hierarchical sparse regression problem\n",
      "first , we discard irrelevant inputs using an extremely fast input ranking heuristic\n",
      "secondly , we take advantage of modern cutting plane methods for integer optimization to solve our resulting reduced hierarchical $ ( k , \\ell ) $ -sparse problem exactly\n",
      "the ability of our method to identify all $ k $ relevant inputs and all $ \\ell $ monomial terms is shown empirically to experience a phase transition\n",
      "crucially , the same transition also presents itself in our ability to reject all irrelevant features and monomials as well\n",
      "in the regime where our method is statistically powerful , its computational complexity is interestingly on par with lasso based heuristics\n",
      "the presented work fills a void in terms of a lack of powerful disciplined nonlinear sparse regression methods in high-dimensional settings\n",
      "our method is shown empirically to scale to regression problems with $ n\\approx 10,000 $ observations for input dimension $ p\\approx 1,000 $ .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Kaggle/Cats-vs-Dogs/myenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Kaggle/Cats-vs-Dogs/myenv/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Kaggle/Cats-vs-Dogs/myenv/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Documents/Kaggle/Cats-vs-Dogs/myenv/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-38e06ca93ae9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mconsider_this\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n is this ok ? \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconsider_this\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"yes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mnew_abstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Kaggle/Cats-vs-Dogs/myenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Kaggle/Cats-vs-Dogs/myenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "with open(\"train.dat\") as f:\n",
    "    for line in f:\n",
    "        j = json.loads(line)\n",
    "        title = j[\"title\"]\n",
    "\n",
    "        if title in done or title in done_file or title in ignored_titles:\n",
    "            continue\n",
    "\n",
    "        if any(ignore in j[\"abstract\"] for ignore in ['i.e .', 'e.g .', 'etc .']):\n",
    "            continue\n",
    "\n",
    "        abstract = j[\"abstract\"].split(\" . \")\n",
    "        print(\"\\n\\n***************************** Abstract is: **************************\")\n",
    "        print(\"\\n\".join(abstract))\n",
    "\n",
    "        consider_this = input(\"\\n is this ok ? \\n\")\n",
    "        if consider_this in [\"yes\", \"y\"]:\n",
    "            new_abstract = []\n",
    "            for a in abstract:\n",
    "                labelling = input(a)\n",
    "                new_abstract.append((dictionary[labelling], a))\n",
    "\n",
    "            j[\"abstract\"] = new_abstract\n",
    "            write_to_file.append(j)\n",
    "            done.add(title)\n",
    "            \n",
    "            if c % 20 == 0:\n",
    "                break\n",
    "            c += 1    \n",
    "            \n",
    "        else:\n",
    "            ignored_titles.add(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 24, 24, 692)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ignored_titles), len(done), len(write_to_file), len(done_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ignored.txt\", \"w\") as f2:\n",
    "    with open(\"labelled.txt\", \"a\") as f:\n",
    "        with open(\"done.txt\", \"a\") as f1:\n",
    "            for i in ignored_titles:\n",
    "                f2.write(i+\"\\n\")\n",
    "            for t in done:\n",
    "                f1.write(t+\"\\n\")\n",
    "            for a in write_to_file:\n",
    "                f.write(json.dumps(a)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
