{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate ACL Questions to Ids\n",
    "The below code associates array indices to the actual question Id in the response. It will be easier to parse the responses using these mappings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "turing_block1_A = ['QID1'] + ['QID' + str(i) for i in range(334, 353)]\n",
    "turing_block1_B = ['QID' + str(i) for i in range(405, 421)] + ['QID422', 'QID423', 'QID424', 'QID476']\n",
    "\n",
    "turing_block2_A = ['QID333'] + ['QID' + str(i) for i in range(353, 372)]\n",
    "turing_block2_B = ['QID' + str(i) for i in range(425, 443)] + ['QID444', 'QID445']\n",
    "\n",
    "qualitative_block_A = ['QID' + str(i) for i in range(374, 383)] + ['QID' + str(i) for i in range(384, 405)]\n",
    "qualitative_block_B = ['QID' + str(i) for i in range(446, 476)]\n",
    "\n",
    "turing_block1_A = {k:i for i, k in enumerate(turing_block1_A)}\n",
    "turing_block1_B = {k:i for i, k in enumerate(turing_block1_B)}\n",
    "turing_block2_A = {k:i for i, k in enumerate(turing_block2_A)}\n",
    "turing_block2_B = {k:i for i, k in enumerate(turing_block2_B)}\n",
    "qualitative_block_A = {k:i for i, k in enumerate(qualitative_block_A)}\n",
    "qualitative_block_B = {k:i for i, k in enumerate(qualitative_block_B)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associate XMLA Questions to Ids\n",
    "The below code associates array indices to the actual question Id in the response. It will be easier to parse the responses using these mappings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "turing_block1_A = ['QID1'] + ['QID' + str(i) for i in range(334, 353)]\n",
    "turing_block1_B = ['QID' + str(i) for i in range(477, 497)]\n",
    "\n",
    "turing_block2_A = ['QID333'] + ['QID' + str(i) for i in range(353, 372)]\n",
    "turing_block2_B = ['QID' + str(i) for i in range(499, 519)]\n",
    "\n",
    "qualitative_block_A = ['QID' + str(i) for i in range(374, 383)] + ['QID' + str(i) for i in range(384, 405)]\n",
    "qualitative_block_B = ['QID' + str(i) for i in range(519, 549)]\n",
    "\n",
    "turing_block1_A = {k:i for i, k in enumerate(turing_block1_A)}\n",
    "turing_block1_B = {k:i for i, k in enumerate(turing_block1_B)}\n",
    "turing_block2_A = {k:i for i, k in enumerate(turing_block2_A)}\n",
    "turing_block2_B = {k:i for i, k in enumerate(turing_block2_B)}\n",
    "qualitative_block_A = {k:i for i, k in enumerate(qualitative_block_A)}\n",
    "qualitative_block_B = {k:i for i, k in enumerate(qualitative_block_B)}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Turing Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "form = \"acl\"\n",
    "actual_turing_block_1_A = json.loads(open(\"forms/{}/turing/block1/turing_block_A.txt\".format(form)).readline())[\"block\"]\n",
    "actual_turing_block_1_B = json.loads(open(\"forms/{}/turing/block1/turing_block_B.txt\".format(form)).readline())[\"block\"]\n",
    "actual_turing_block_2_A = json.loads(open(\"forms/{}/turing/block2/turing_block_A.txt\".format(form)).readline())[\"block\"]\n",
    "actual_turing_block_2_B = json.loads(open(\"forms/{}/turing/block2/turing_block_B.txt\".format(form)).readline())[\"block\"]\n",
    "qual_block_A = json.loads(open(\"forms/{}/qualitative/block_A.txt\".format(form)).readline())[\"block\"]\n",
    "qual_block_B = json.loads(open(\"forms/{}/qualitative/block_B.txt\".format(form)).readline())[\"block\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer_turing_1(question, abstract_num):\n",
    "    is_kevin = False\n",
    "    num = int(abstract_num.split(\"-\")[1])\n",
    "    for i in range(1, 4):\n",
    "        if question[i][1] == \"Kevin\":\n",
    "            is_kevin = True\n",
    "    return question[num][1] != \"Original\", is_kevin\n",
    "\n",
    "def check_answer_turing_2(question, abstract_num):\n",
    "    is_kevin = False\n",
    "    num = int(abstract_num.split(\"-\")[1]) - 1\n",
    "    for i in range(3):\n",
    "        if question[i][2] == \"Kevin\":\n",
    "            is_kevin = True\n",
    "    return question[num][2] == \"Original\", is_kevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "xmlfile = 'forms/{}/{}_responses.xml'.format(form, form)\n",
    "tree = ET.parse(xmlfile) \n",
    "root = tree.getroot()\n",
    "\n",
    "# Same title stats\n",
    "same_title_pass_kevin = 0\n",
    "same_title_pass_wepgen = 0\n",
    "same_title_kevin_total = 0\n",
    "same_title_wepgen_total = 0\n",
    "\n",
    "# Diff title stats\n",
    "diff_title_pass_kevin = 0\n",
    "diff_title_pass_wepgen = 0\n",
    "diff_title_kevin_total = 0\n",
    "diff_title_wepgen_total = 0\n",
    "\n",
    "for human in root:\n",
    "    if human.find('finished').text == \"True\":\n",
    "        \"\"\"\n",
    "            Turing Block 1\n",
    "        \"\"\"\n",
    "                \n",
    "        block_1 = turing_block1_A if human.find('QID1').text else turing_block1_B\n",
    "        actual_block_1 = actual_turing_block_1_A if human.find('QID1').text else actual_turing_block_1_B\n",
    "        for question_id in block_1:\n",
    "            response = human.find(question_id).text\n",
    "            index = block_1[question_id]\n",
    "            answer, is_kevin = check_answer_turing_1(actual_block_1[index], response)\n",
    "            if answer:\n",
    "                same_title_pass_kevin += (is_kevin)\n",
    "                same_title_pass_wepgen += (not is_kevin)\n",
    "                \n",
    "            same_title_kevin_total += (is_kevin)   \n",
    "            same_title_wepgen_total += (not is_kevin)\n",
    "       \n",
    "        \"\"\"\n",
    "            Turing Block 2\n",
    "        \"\"\"\n",
    "        block_2 = turing_block2_A if human.find('QID333').text else turing_block2_B\n",
    "        actual_block_2 = actual_turing_block_2_A if human.find('QID333').text else actual_turing_block_2_B\n",
    "        for question_id in block_2:\n",
    "            response = human.find(question_id).text\n",
    "            index = block_2[question_id]\n",
    "            answer, is_kevin = check_answer_turing_2(actual_block_2[index], response)\n",
    "            if answer:\n",
    "                diff_title_pass_kevin += (is_kevin)\n",
    "                diff_title_pass_wepgen += (not is_kevin)\n",
    "                \n",
    "            diff_title_kevin_total += (is_kevin)   \n",
    "            diff_title_wepgen_total += (not is_kevin)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 65), (240, 57))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(same_title_kevin_total, same_title_pass_kevin), (same_title_wepgen_total, same_title_pass_wepgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 74), (240, 72))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(diff_title_kevin_total, diff_title_pass_kevin), (diff_title_wepgen_total, diff_title_pass_wepgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculates the ratings from the qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET \n",
    "\n",
    "qual_mappings = {'1': 'Coherence', '2': 'Structural Relevance',\n",
    "                 '3': 'Fluency', '4': 'Grammatical Efficiency',\n",
    "                 '5': 'Relevance to the Title'}\n",
    "score_mappings = {'Very High': 5, 'High': 4, 'Average': 3, \n",
    "                  'Low': 2, 'Very Low': 1}\n",
    "\n",
    "xmlfile = 'forms/acl/acl_responses.xml'\n",
    "tree = ET.parse(xmlfile) \n",
    "root = tree.getroot()\n",
    "qual_total = {}\n",
    "kevin_score = {}\n",
    "WEPGen_score = {}\n",
    "org_score = {}\n",
    "for human in root:\n",
    "    if human.find('finished').text == \"True\":\n",
    "        qual_block = qualitative_block_A if human.find('QID374_1').text else qualitative_block_B\n",
    "        actual_qual_block = qual_block_A if human.find('QID374_1').text else qual_block_B\n",
    "        for question_id in qual_block:\n",
    "            index = qual_block[question_id]\n",
    "            qual_total[actual_qual_block[index][2]] = qual_total.get(actual_qual_block[index][2], 0) + 1\n",
    "            for i in range(1, 6):\n",
    "                q_id = question_id + \"_\" + str(i)\n",
    "                response = human.find(q_id).text\n",
    "                if actual_qual_block[index][2] == \"Kevin\":\n",
    "                    kevin_score[i] = kevin_score.get(i, 0) + score_mappings[response]\n",
    "                elif actual_qual_block[index][2] == \"WEPGen\":\n",
    "                    WEPGen_score[i] = WEPGen_score.get(i, 0) + score_mappings[response]\n",
    "                else:\n",
    "                    org_score[i] = org_score.get(i, 0) + score_mappings[response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WEPGen': 220, 'Original': 220, 'Kevin': 220}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.089473684210526,\n",
       " 4.1,\n",
       " 4.105263157894737,\n",
       " 4.2631578947368425,\n",
       " 4.147368421052631]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[kevin_score[k] / 190 for k in kevin_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.9368421052631577,\n",
       " 4.021052631578947,\n",
       " 4.015789473684211,\n",
       " 3.931578947368421,\n",
       " 3.957894736842105]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[WEPGen_score[k] / 190 for k in WEPGen_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.710526315789474,\n",
       " 3.8210526315789473,\n",
       " 3.6842105263157894,\n",
       " 3.805263157894737,\n",
       " 3.836842105263158]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[org_score[k] / 190 for k in WEPGen_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
